{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_ehzCJDTxUb"
   },
   "source": [
    "# Первый этап обучения\n",
    "\n",
    "## Решаем задачу сегментации на разрешении изображений 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKznVgHinjSV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Загрузка датасета\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    !cp /content/drive/MyDrive/crimea/train_crimea.zip /content/\n",
    "    !unzip -oq /content/train_crimea.zip\n",
    "\n",
    "    !cp /content/drive/MyDrive/crimea/test_crimea.zip /content/\n",
    "    !unzip -oq /content/test_crimea.zip\n",
    "\n",
    "    !mkdir /content/test_masks\n",
    "\n",
    "    !python -m pip install --upgrade pip\n",
    "    !pip install -U segmentation_models_pytorch\n",
    "\n",
    "    COLAB      = True\n",
    "    ROOT       = '/content/'\n",
    "    ROOT_DRIVE = '/content/drive/MyDrive/crimea/'\n",
    "\n",
    "except:\n",
    "    COLAB      = False\n",
    "    ROOT       = './'\n",
    "    ROOT_DRIVE = './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhKhEfYRoXt1",
    "outputId": "43517f34-07b0-4b61-9981-45591ff9d2a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 20 13:38:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9kjOjiknfsb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "SEED = 1\n",
    "SIZE = 512\n",
    "STAGE = 1\n",
    "DEVICE = 'cuda'\n",
    "EPOCHS = 15\n",
    "MAX_LR = 1e-4\n",
    "BATCHSIZE = 12\n",
    "\n",
    "ARCH = 'DeepLabV3Plus'\n",
    "ENCODER = 'tu-xception71'\n",
    "PREVIOUS= f'stage_{STAGE - 1}'\n",
    "VERSION = f'stage_{STAGE}'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", 'User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
    "warnings.filterwarnings(\"ignore\", 'torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заменяем классификационный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEmCAHmDQhNz"
   },
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(encoder_name=ENCODER,\n",
    "                          encoder_weights=None, classes=3) # RGB\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{ROOT_DRIVE}{ARCH}_{ENCODER}_{PREVIOUS}.pth\",\n",
    "                                 map_location='cpu'))\n",
    "\n",
    "\n",
    "model.segmentation_head[0] = nn.Conv2d(256, 4,\n",
    "                                       kernel_size=(1, 1),\n",
    "                                       stride=(1, 1))\n",
    "torch.nn.init.xavier_uniform_(model.segmentation_head[0].weight)\n",
    "model.segmentation_head[0].bias.data.fill_(0.0)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQdUkfIbnfse",
    "outputId": "ba454f92-66e6-41d0-f596-a6cf2433c9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(ROOT)\n",
    "\n",
    "train_image_path = ROOT / \"images\"\n",
    "train_mask_path = ROOT / \"masks\"\n",
    "\n",
    "ALL_IMAGES = sorted(train_image_path.glob(\"*.png\"))\n",
    "ALL_MASKS = sorted(train_mask_path.glob(\"*.png\"))\n",
    "\n",
    "assert len(ALL_IMAGES) == len(ALL_MASKS)\n",
    "\n",
    "print(len(ALL_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO1f-y8infsf"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "seed_everything(SEED + STAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6Ira3mbnfsg"
   },
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit  = 0.05,\n",
    "                       scale_limit  = 0.05,\n",
    "                       rotate_limit = 15,\n",
    "                       p=1.0),\n",
    "    A.Resize(SIZE, SIZE, interpolation=cv2.INTER_AREA),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.PiecewiseAffine(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2, p=1),\n",
    "        A.Sharpen(p=1),\n",
    "        A.Emboss(p=1),\n",
    "    ], p=0.3),\n",
    "    A.ColorJitter(hue=0.03, p=1.0),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(SIZE, SIZE, interpolation=cv2.INTER_AREA),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElvJQrlOf4Gm"
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: List[Path],\n",
    "        masks: List[Path] = None,\n",
    "        transforms=None\n",
    "    ) -> None:\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        image_path = self.images[idx]\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "        \n",
    "        result = {\"image\": image, \"hw\": [h, w]}\n",
    "        \n",
    "        if self.masks is not None:\n",
    "            mask = cv2.imread(str(self.masks[idx]), 0)\n",
    "            result[\"mask\"] = mask\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            result = self.transforms(**result)\n",
    "        \n",
    "        result[\"filename\"] = image_path.name\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjPllg3Snfsi"
   },
   "outputs": [],
   "source": [
    "all_images = np.asarray(ALL_IMAGES)\n",
    "all_masks  = np.asarray(ALL_MASKS)\n",
    "\n",
    "train_img, test_img, train_mask, test_mask = train_test_split(all_images, all_masks,\n",
    "                                                              random_state=SEED, test_size=0.05)\n",
    "\n",
    "dataset_train = SegmentationDataset(train_img, masks=train_mask, transforms=transform_train)\n",
    "dataset_val   = SegmentationDataset(test_img, masks=test_mask, transforms=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0bnNOqZnfsj"
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(DEVICE)\n",
    "\n",
    "dice      = smp.losses.DiceLoss(mode='multiclass', classes=[1, 2, 3],\n",
    "                                log_loss=False, from_logits=True,\n",
    "                                smooth=1.0, eps=1e-08)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "iou       = smp.losses.JaccardLoss(mode='multiclass',\n",
    "                                   classes=[1, 2, 3], log_loss=False,\n",
    "                                   smooth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meU5oSqhQhN3"
   },
   "source": [
    "## Pretrain head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oLdP6_1QhN4",
    "outputId": "0cd746b6-4569-46c2-fed0-40d02b82c881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start at 13:41:28\n",
      "done at 13:50:33\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.segmentation_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "\n",
    "loader_train = DataLoader(\n",
    "  dataset_train,\n",
    "  batch_size=8,\n",
    "  shuffle=True,\n",
    "  num_workers=2,\n",
    "  drop_last=True,\n",
    ")\n",
    "\n",
    "print('start at', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "for i, batch in enumerate(loader_train, start=1):\n",
    "    mask = batch['mask'].to(DEVICE)\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        pred = model.forward(batch['image'].to(DEVICE))\n",
    "\n",
    "        dc = dice(pred, mask.long())\n",
    "        y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "        y_true = (mask > 0).float()\n",
    "        bce = criterion(y_pred, y_true)\n",
    "\n",
    "        loss = dc + bce * 0.1\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "print('done at', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gB9AXmysnfsj"
   },
   "source": [
    "## Start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruFF2rqpnfsm",
    "outputId": "4e01fa30-5392-4503-889a-a158b007dae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start at 13:50:35\n",
      "14:00:16 epoch 00 loss 0.988 bce 0.853 dice 0.902 lr=0.00002207\n",
      "14:00:27 valid    loss 1.020 bce 0.850 dice 0.850 metric 0.089\n",
      "Save model\n",
      "14:10:04 epoch 01 loss 0.645 bce 0.724 dice 0.573 lr=0.00006268\n",
      "14:10:14 valid    loss 0.513 bce 0.683 dice 0.377 metric 0.470\n",
      "Save model\n",
      "14:20:03 epoch 02 loss 0.425 bce 0.678 dice 0.357 lr=0.00009525\n",
      "14:20:13 valid    loss 0.437 bce 0.673 dice 0.302 metric 0.556\n",
      "Save model\n",
      "14:29:57 epoch 03 loss 0.375 bce 0.673 dice 0.307 lr=0.00009944\n",
      "14:30:08 valid    loss 0.412 bce 0.671 dice 0.278 metric 0.588\n",
      "Save model\n",
      "14:39:52 epoch 04 loss 0.356 bce 0.672 dice 0.289 lr=0.00009507\n",
      "14:40:03 valid    loss 0.393 bce 0.669 dice 0.259 metric 0.609\n",
      "Save model\n",
      "14:49:44 epoch 05 loss 0.337 bce 0.671 dice 0.270 lr=0.00008671\n",
      "14:49:55 valid    loss 0.386 bce 0.669 dice 0.253 metric 0.618\n",
      "Save model\n",
      "14:59:33 epoch 06 loss 0.326 bce 0.670 dice 0.259 lr=0.00007510\n",
      "14:59:44 valid    loss 0.371 bce 0.668 dice 0.238 metric 0.639\n",
      "Save model\n",
      "15:09:26 epoch 07 loss 0.318 bce 0.669 dice 0.251 lr=0.00006128\n",
      "15:09:37 valid    loss 0.367 bce 0.666 dice 0.234 metric 0.644\n",
      "Save model\n",
      "15:19:37 epoch 08 loss 0.309 bce 0.669 dice 0.242 lr=0.00004648\n",
      "15:19:47 valid    loss 0.366 bce 0.667 dice 0.233 metric 0.648\n",
      "Save model\n",
      "15:29:23 epoch 09 loss 0.304 bce 0.668 dice 0.238 lr=0.00003201\n",
      "15:29:34 valid    loss 0.365 bce 0.667 dice 0.232 metric 0.649\n",
      "Save model\n",
      "15:39:11 epoch 10 loss 0.299 bce 0.668 dice 0.232 lr=0.00001915\n",
      "15:39:21 valid    loss 0.357 bce 0.666 dice 0.224 metric 0.658\n",
      "Save model\n",
      "15:49:12 epoch 11 loss 0.292 bce 0.668 dice 0.225 lr=0.00000905\n",
      "15:49:23 valid    loss 0.356 bce 0.666 dice 0.222 metric 0.660\n",
      "Save model\n",
      "15:59:09 epoch 12 loss 0.291 bce 0.668 dice 0.224 lr=0.00000261\n",
      "15:59:19 valid    loss 0.356 bce 0.666 dice 0.222 metric 0.661\n",
      "Save model\n",
      "16:09:02 epoch 13 loss 0.289 bce 0.667 dice 0.222 lr=0.00000040\n",
      "16:09:12 valid    loss 0.355 bce 0.666 dice 0.222 metric 0.661\n",
      "Save model\n",
      "16:18:51 epoch 14 loss 0.289 bce 0.668 dice 0.222 lr=0.00000261\n",
      "16:19:02 valid    loss 0.354 bce 0.666 dice 0.221 metric 0.662\n",
      "Save model\n",
      "done at 16:19:02\n"
     ]
    }
   ],
   "source": [
    "loader_train = DataLoader(\n",
    "  dataset_train,\n",
    "  batch_size=BATCHSIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=2,\n",
    "  drop_last=True,\n",
    ")\n",
    "\n",
    "loader_val = DataLoader(\n",
    "  dataset_val,\n",
    "  batch_size=BATCHSIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=2,\n",
    "  drop_last=False,\n",
    ")\n",
    "\n",
    "seed_everything(SEED + STAGE)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=MAX_LR,\n",
    "                              weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                epochs=EPOCHS,\n",
    "                                                max_lr=MAX_LR,\n",
    "                                                div_factor=25.0,\n",
    "                                                final_div_factor=10.0,\n",
    "                                                steps_per_epoch=1)\n",
    "\n",
    "print('start at', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "best_metric = 0.0\n",
    "best_cnt    = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    losses     = []\n",
    "    losses_bce = []\n",
    "    losses_dc  = []\n",
    "\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for i, batch in enumerate(loader_train, start=1):\n",
    "        mask = batch['mask'].to(DEVICE)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            pred = model.forward(batch['image'].to(DEVICE))\n",
    "            \n",
    "            dc = dice(pred, mask.long())\n",
    "            y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "            y_true = (mask > 0).float()\n",
    "            bce = criterion(y_pred, y_true)\n",
    "            \n",
    "            loss = dc + bce * 0.1\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        losses_bce.append(bce.item())\n",
    "        losses_dc.append(dc.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "    scheduler.step()\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"),\n",
    "          f'epoch {epoch:02d} loss {np.mean(losses):.3f} bce {np.mean(losses_bce):.3f} '\n",
    "          f'dice {np.mean(losses_dc):.3f} lr={optimizer.param_groups[0][\"lr\"]:.8f}')\n",
    "\n",
    "    val_losses     = []\n",
    "    val_losses_bce = []\n",
    "    val_losses_dc  = []\n",
    "    metrics        = []\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_val:\n",
    "            pred = model.forward(batch['image'].to(DEVICE))\n",
    "            mask = batch['mask'].to(DEVICE)\n",
    "\n",
    "            dc = dice(pred, mask.long())\n",
    "            y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "            y_true = (mask > 0).float()\n",
    "            bce = criterion(y_pred, y_true)\n",
    "\n",
    "            loss = dc + bce * 0.2\n",
    "            metric = 1 - iou(pred, mask.long()).item()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_losses_bce.append(bce.item())\n",
    "            val_losses_dc.append(dc.item())\n",
    "\n",
    "            metrics.append(metric)\n",
    "\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"), f'valid    loss {np.mean(val_losses):.3f} bce {np.mean(val_losses_bce):.3f} '\n",
    "          f'dice {np.mean(val_losses_dc):.3f} metric {np.mean(metrics):.3f}')\n",
    "\n",
    "    best_cnt += 1\n",
    "    if best_metric <= np.mean(metrics):\n",
    "        best_cnt    = 0\n",
    "        best_metric = np.mean(metrics)\n",
    "        torch.save(model.state_dict(), f\"{ROOT_DRIVE}{ARCH}_{ENCODER}_{VERSION}.pth\")\n",
    "        print('Save model')\n",
    "    if best_cnt > 3:\n",
    "        best_cnt = 0\n",
    "        model.load_state_dict(torch.load(f\"{ROOT_DRIVE}{ARCH}_{ENCODER}_{VERSION}.pth\", map_location='cpu'))\n",
    "        print('Reload model')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('done at', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX9hoRMdR0M2"
   },
   "source": [
    "## Делаем прогноз\n",
    "\n",
    "После первого этапа результат будет не очень хорошим, но он должен подтвердить верность направления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iN2g9GPRx2o",
    "outputId": "f64875e2-2958-493a-b1e7-c157eacb06f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 /content/test/00388128-357d-44bb-a630-5e8856e4dcb0.png\n",
      "0100 /content/test/0c2d854d-01e5-4b6e-ba78-1b443edcd784.png\n",
      "0200 /content/test/1af2e8a6-c3e3-4e80-b6b9-1ef8d693a57f.png\n",
      "0300 /content/test/2aadb686-e5ec-4c3d-bcb1-b76e3030c62e.png\n",
      "0400 /content/test/3aa52680-b2f0-487a-b6c7-e38050a4a04e.png\n",
      "0500 /content/test/4ac6f8a4-957b-4be7-aee6-f40019dbe356.png\n",
      "0600 /content/test/58b3ccd9-4c6d-477b-8dd0-6b09dfe73d5d.png\n",
      "0700 /content/test/619d426b-4a34-4d46-ad9e-45a8ece730dd.png\n",
      "0800 /content/test/6f431a1c-0a6c-480d-bffd-629b0fbd7a0d.png\n",
      "0900 /content/test/7bec62bf-f5ef-4d0e-b525-0f30aca7f60f.png\n",
      "1000 /content/test/8b3e4e4c-3499-4fad-9f87-02073fed2fd2.png\n",
      "1100 /content/test/9b793582-e744-450c-a142-e34d0a7cb2ec.png\n",
      "1200 /content/test/b32baacd-bf29-49e9-b2eb-9a718ea4496d.png\n",
      "1300 /content/test/bf3e649d-db84-433e-9f4c-82b7f040c226.png\n",
      "1400 /content/test/de171555-fcde-48e1-9d11-b5f16a3997a8.png\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{ROOT_DRIVE}{ARCH}_{ENCODER}_{VERSION}.pth\",\n",
    "                                 map_location='cpu'))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(SIZE, SIZE, interpolation=cv2.INTER_AREA),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_image_path = Path(ROOT) / \"test\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    for i, image_path in enumerate(sorted(test_image_path.glob(\"*.png\"))):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i:04d} {image_path}\")\n",
    "\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        img  = transform_test(image=img)['image'].unsqueeze(0).to(DEVICE)\n",
    "        pred = model.forward(img)\n",
    "        mask = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
    "        mask = cv2.resize(mask, (w, h), 0, 0, interpolation=cv2.INTER_NEAREST)\n",
    "                \n",
    "        cv2.imwrite(f'{str(ROOT)}/test_masks/{image_path.name}', mask)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gee_DNuoSPg5",
    "outputId": "6984a122-9d6f-4515-f8ec-66e6e0dc3e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/test_masks\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "    %cd /content/test_masks/\n",
    "    !zip -q ../test_masks_1.zip *.png\n",
    "    !cp ../test_masks_1.zip /content/drive/MyDrive/crimea/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
