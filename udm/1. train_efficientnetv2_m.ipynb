{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8b1c19-ea6d-4f9d-8cfd-cba841ca3cf4",
   "metadata": {},
   "source": [
    "## Определяем среду исполнения, для коллаба работаем с данными на Google Drive\n",
    "\n",
    "Данный ноутбук исполнялся на домашнем компьютере, поэтому все исходные изображения должны быть помещены в подкаталог train и test соответственно, табличные данные - в текущий каталог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71cc4c9-208a-4db4-b302-72f3a31363e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c71cc4c9-208a-4db4-b302-72f3a31363e2",
    "outputId": "4dd70e74-d3bb-4429-c352-e7f6554d905a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 12 23:00:06 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   54C    P0    61W / 200W |     19MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1235      G   /usr/lib/xorg/Xorg                 14MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    num_workers = 2\n",
    "    BATCHSIZE = 32\n",
    "    ROOT = '/content/'\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    !cp /content/drive/MyDrive/2022_udm.zip /content/2022_udm.zip\n",
    "    !unzip -q /content/2022_udm.zip -d /content/\n",
    "\n",
    "    !python -m pip install --upgrade pip\n",
    "    !pip install -U timm albumentations opencv-contrib-python pytorch_metric_learning\n",
    "else:\n",
    "    num_workers = 4\n",
    "    ROOT = './'\n",
    "    BATCHSIZE = 16\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13494c2a-e2d0-4a13-939a-aa9333eed365",
   "metadata": {},
   "source": [
    "## Определяем основные библиотеки, загружаем предобученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddf2826-5bd7-4398-8029-4e42b9a0fde4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ddf2826-5bd7-4398-8029-4e42b9a0fde4",
    "outputId": "38cfae07-e62a-4ae9-c8e4-8675ece5eba5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "TIMMMODEL = 'tf_efficientnetv2_m_in21ft1k'\n",
    "SIZE = 384\n",
    "\n",
    "SEED = 111\n",
    "DEVICE = 'cuda'\n",
    "VERSION = '1207'\n",
    "EPOCHS = 200\n",
    "EMB_FEATURES = 256\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "model = timm.create_model(TIMMMODEL, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a11d366-5111-4f51-a83f-0cd6b8140ed3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a11d366-5111-4f51-a83f-0cd6b8140ed3",
    "outputId": "2dd738a7-980c-45b2-e601-39b5a2fb0a51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_m_21ft1k-bf41664a.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 384, 384),\n",
       " 'pool_size': (12, 12),\n",
       " 'crop_pct': 1.0,\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.5, 0.5, 0.5),\n",
       " 'std': (0.5, 0.5, 0.5),\n",
       " 'first_conv': 'conv_stem',\n",
       " 'classifier': 'classifier',\n",
       " 'test_input_size': (3, 480, 480),\n",
       " 'architecture': 'tf_efficientnetv2_m_in21ft1k'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.default_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e3821-54d5-493a-9b57-e63d50fc70ff",
   "metadata": {},
   "source": [
    "## Зафиксируем ГСЧ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d991b7f5-606b-463a-b3e2-fd08591ec474",
   "metadata": {
    "id": "d991b7f5-606b-463a-b3e2-fd08591ec474"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e3eda-ebb9-4575-b722-4d6aee49a9c9",
   "metadata": {},
   "source": [
    "## Определим класс датасета и аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd34b5e7-d03f-4e0d-aad3-d59e48a4433c",
   "metadata": {
    "id": "fd34b5e7-d03f-4e0d-aad3-d59e48a4433c"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['img_num']\n",
    "\n",
    "        image = cv2.imread(f\"{ROOT}train/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        label = self.data_df.iloc[idx]['number_of_houses']\n",
    "\n",
    "        return image, torch.tensor(min(label, 26)).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "\n",
    "transform_train = A.Compose([\n",
    "    A.Resize(SIZE, SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.OneOf([\n",
    "      A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.4, p=0.2),\n",
    "      A.RandomShadow(p=0.2),\n",
    "    ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GridDistortion(p=.1),\n",
    "        A.PiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(),\n",
    "        A.Emboss(),\n",
    "        A.RandomBrightnessContrast(),            \n",
    "    ], p=0.3),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.Normalize(mean= model.default_cfg['mean'],\n",
    "                std = model.default_cfg['std']),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(SIZE, SIZE),\n",
    "    A.Normalize(mean= model.default_cfg['mean'],\n",
    "                std = model.default_cfg['std']),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0175dfbf-4a76-4553-8080-20958d522d31",
   "metadata": {},
   "source": [
    "## Отбросим все изображения, где черного фона более 25% или где количество сооружений больше 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afee5a1-c7d1-4398-9478-cf505bcc7b2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7afee5a1-c7d1-4398-9478-cf505bcc7b2a",
    "outputId": "34298aa3-3707-4666-c654-548aa8d90f0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     200\n",
       "10    139\n",
       "2     139\n",
       "3     137\n",
       "4     134\n",
       "8     133\n",
       "11    133\n",
       "6     126\n",
       "5     116\n",
       "9     113\n",
       "7     110\n",
       "13    108\n",
       "14    103\n",
       "12     94\n",
       "15     85\n",
       "16     63\n",
       "17     40\n",
       "18     31\n",
       "19     21\n",
       "20     11\n",
       "21     11\n",
       "22     10\n",
       "24      4\n",
       "23      4\n",
       "25      4\n",
       "Name: number_of_houses, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_list = []\n",
    "data_df = pd.read_csv(f'{ROOT}train.csv')\n",
    "for i in range(len(data_df)):\n",
    "    img = cv2.imread('train/' + data_df.iloc[i]['img_num'])\n",
    "    mask = (img[:, :, 0] < 5).sum() / (img.shape[0] * img.shape[1])\n",
    "    if mask > 0.25:\n",
    "        ignore_list.append(data_df.iloc[i]['img_num'])\n",
    "\n",
    "data_df = data_df[~data_df['img_num'].isin(ignore_list)].copy()\n",
    "data_df = data_df[data_df['number_of_houses'] < 27].copy()\n",
    "\n",
    "data_df['number_of_houses'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0dc6c-866b-4f3c-a807-602411538d7b",
   "metadata": {},
   "source": [
    "## Инициализируем даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841fa545-28df-4a64-bc3e-efca72ad2a71",
   "metadata": {
    "id": "841fa545-28df-4a64-bc3e-efca72ad2a71"
   },
   "outputs": [],
   "source": [
    "dataset_train = ImageDataset(data_df, transform_train)\n",
    "dataset_val   = ImageDataset(data_df, transform_val)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                           batch_size=BATCHSIZE,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=num_workers)\n",
    "loader_val   = torch.utils.data.DataLoader(dataset=dataset_val,\n",
    "                                           batch_size=BATCHSIZE * 2,\n",
    "                                           shuffle=False,\n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=False,\n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37e013-d167-4441-baed-2799559a2f24",
   "metadata": {},
   "source": [
    "## Создадим требуемые нам головы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18b9c8f-d0db-4732-b28b-d94c6e305682",
   "metadata": {
    "id": "b18b9c8f-d0db-4732-b28b-d94c6e305682"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_features, emb_features:int=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.emb_features = emb_features\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(self.in_features, self.emb_features, bias=False),\n",
    "            nn.BatchNorm1d(self.emb_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.emb_features, 1)\n",
    "        )\n",
    "        self.neck = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_features),\n",
    "            nn.Linear(self.in_features, self.emb_features, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(self.emb_features),\n",
    "            nn.Linear(self.emb_features, self.emb_features, bias=False),\n",
    "            nn.BatchNorm1d(self.emb_features)\n",
    "        )\n",
    "\n",
    "        torch.nn.init.xavier_normal_(self.neck[1].weight)\n",
    "        torch.nn.init.xavier_normal_(self.neck[4].weight)\n",
    "\n",
    "        torch.nn.init.xavier_normal_(self.out[0].weight)\n",
    "        torch.nn.init.xavier_normal_(self.out[3].weight)\n",
    "        torch.nn.init.zeros_(self.out[3].bias)\n",
    "        \n",
    "        \n",
    "    def forward(self, features):\n",
    "        x = self.dropout(features)\n",
    "        x_ = self.neck(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x, x_\n",
    "\n",
    "\n",
    "head_name = model.default_cfg['classifier']\n",
    "\n",
    "\n",
    "# Различные модели имеют различный выходной слой классификатора\n",
    "if head_name == 'last_linear':\n",
    "    model.last_linear = Head(model.last_linear.in_features, emb_features=EMB_FEATURES)\n",
    "elif head_name == 'head':\n",
    "    model.head = Head(model.head.in_features, emb_features=EMB_FEATURES)\n",
    "elif head_name == 'fc':\n",
    "    model.fc = Head(model.fc.in_features, emb_features=EMB_FEATURES)\n",
    "elif head_name == 'classifier':\n",
    "    model.classifier = Head(model.classifier.in_features, emb_features=EMB_FEATURES)\n",
    "\n",
    "\n",
    "_ = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77310155-147d-4d0a-9cf4-bcc1af3ec279",
   "metadata": {},
   "source": [
    "## Основной цикл обучения и сохранения весов модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a343b87b-d760-4a95-bf92-569b9a2e9e4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "a343b87b-d760-4a95-bf92-569b9a2e9e4a",
    "outputId": "af3fe0c4-5919-4247-8a37-a476b619dd92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:13:56 - 06:16:05 200/200 epoch cls 0.3210 arc 1.1238 validate R2 0.9967\n",
      "total 26149 seconds\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                                 T_0=10, \n",
    "                                                                 T_mult=1, \n",
    "                                                                 eta_min=1e-6,\n",
    "                                                                 last_epoch=-1)      \n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion_ = ArcFaceLoss(28, EMB_FEATURES).to(DEVICE)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    losses  = []\n",
    "    losses_ = []\n",
    "    model.train()\n",
    "    start_date = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f'{start_date} start train {epoch + 1}/{EPOCHS} epoch')\n",
    "    for it, (imgs, labels) in enumerate(loader_train, start = 1):\n",
    "        if it % 100 == 0:\n",
    "            print(f'{datetime.now().strftime(\"%H:%M:%S\")} iter {it:5d}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            y_pred, y_pred_ = model(imgs)\n",
    "            loss = criterion(y_pred, labels.float().unsqueeze(1))\n",
    "            loss_ = criterion_(y_pred_, labels)\n",
    "            \n",
    "        scaler.scale(loss * 0.8 + loss_ * 0.2).backward()\n",
    "        losses.append(loss.item())\n",
    "        losses_.append(loss_.item())\n",
    "        \n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    scheduler.step()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    print(f'{datetime.now().strftime(\"%H:%M:%S\")} start validate')\n",
    "    for it, (imgs, labels) in enumerate(loader_val, start = 1):\n",
    "        if it % 100 == 0:\n",
    "            print(f'{datetime.now().strftime(\"%H:%M:%S\")} iter {it:5d}')\n",
    "        \n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        valid_labels = []\n",
    "        valid_predicts = []\n",
    "        with torch.no_grad():\n",
    "            y_pred, _ = model(imgs)\n",
    "\n",
    "        pred = torch.clip(y_pred, 1.0, 26.0)\n",
    "        pred = torch.ceil(pred)\n",
    "\n",
    "        pred_numpy = pred.cpu().numpy().astype('int').flatten()\n",
    "        valid_predicts.extend(pred_numpy.tolist())\n",
    "        valid_labels.extend(labels.cpu().numpy().astype('int').flatten().tolist())\n",
    "\n",
    "    val_r2 = r2_score(valid_labels, valid_predicts)\n",
    "        \n",
    "\n",
    "    if IN_COLAB:\n",
    "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/chkp/{VERSION}_{TIMMMODEL}_arc.pth\")\n",
    "        if val_r2 > 0.90:\n",
    "            torch.save(model.state_dict(), f\"/content/drive/MyDrive/chkp/{VERSION}_{TIMMMODEL}_arc_{epoch:03d}_r2-{val_r2:.4f}.pth\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f\"{VERSION}_{TIMMMODEL}_arc.pth\")\n",
    "        if val_r2 > 0.90:\n",
    "            torch.save(model.state_dict(), f\"{VERSION}_{TIMMMODEL}_arc_{epoch:03d}_r2-{val_r2:.4f}.pth\")\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    print(f'{start_date} - {datetime.now().strftime(\"%H:%M:%S\")} {epoch + 1}/{EPOCHS} epoch cls {np.mean(losses):.4f} arc {np.mean(losses_):.4f} validate R2 {val_r2:.4f}')\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"total {time.time() - start_time:.0f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "arc0807_train_swin_base_patch4_window7_224_in22k.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
