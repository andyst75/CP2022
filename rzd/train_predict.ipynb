{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "SEED = 1975\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "ARCH = 'DeepLabV3Plus'\n",
    "ENCODER = 'tu-xception71'\n",
    "VERSION = '1807_resize_640x864'\n",
    "\n",
    "model = smp.DeepLabV3Plus(encoder_name=ENCODER, encoder_weights='imagenet', classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем список файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\".\")\n",
    "\n",
    "train_image_path = ROOT / \"train/images\"\n",
    "train_mask_path = ROOT / \"train/mask\"\n",
    "test_image_path = ROOT / \"test\"\n",
    "\n",
    "ALL_IMAGES = sorted(train_image_path.glob(\"*.png\"))\n",
    "ALL_MASKS = sorted(train_mask_path.glob(\"*.png\"))\n",
    "\n",
    "assert len(ALL_IMAGES) == len(ALL_MASKS)\n",
    "\n",
    "print(len(ALL_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фиксируем ГСЧ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготавливаем трансформации для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.Resize(640, 864),\n",
    "    A.CoarseDropout (max_holes=6, max_height=0.1, max_width=0.1, min_holes=2, min_height=0.01, min_width=0.01, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.05),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.2, rotate_limit=12, p=0.50),\n",
    "    A.OneOf([\n",
    "      A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.6, p=0.2),\n",
    "      A.RandomRain(p=0.2),\n",
    "      A.RandomShadow(p=0.2),\n",
    "    ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GridDistortion(p=.1),\n",
    "        A.PiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ToSepia(p=0.1),\n",
    "    ], p=0.1),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(),\n",
    "        A.Emboss(),\n",
    "        A.RandomBrightnessContrast(),            \n",
    "    ], p=0.3),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(640, 864),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описываем класс для работы с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElvJQrlOf4Gm",
    "outputId": "f1f676ac-72b6-437b-f41e-c091724e86a5"
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: List[Path],\n",
    "        masks: List[Path] = None,\n",
    "        transforms=None\n",
    "    ) -> None:\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        image_path = self.images[idx]\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "        \n",
    "        result = {\"image\": image, \"hw\": [h, w]}\n",
    "        \n",
    "        if self.masks is not None:\n",
    "            mask = cv2.imread(str(self.masks[idx]), 0)\n",
    "            mask[mask ==  6] = 1\n",
    "            mask[mask ==  7] = 2\n",
    "            mask[mask == 10] = 3\n",
    "            result[\"mask\"] = mask\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            result = self.transforms(**result)\n",
    "        \n",
    "        result[\"filename\"] = image_path.name\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем даталоадеры, функции потерь, метрику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.asarray(ALL_IMAGES)\n",
    "all_masks  = np.asarray(ALL_MASKS)\n",
    "\n",
    "dataset_train = SegmentationDataset(all_images, masks=all_masks, transforms=transform_train)\n",
    "dataset_val   = SegmentationDataset(all_images, masks=all_masks, transforms=transform_val)\n",
    "\n",
    "loader_train = DataLoader(\n",
    "  dataset_train,\n",
    "  batch_size=6,\n",
    "  shuffle=True,\n",
    "  num_workers=6,\n",
    "  drop_last=True,\n",
    ")\n",
    "\n",
    "loader_val = DataLoader(\n",
    "  dataset_val,\n",
    "  batch_size=8,\n",
    "  shuffle=False,\n",
    "  num_workers=4,\n",
    "  drop_last=False,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "\n",
    "dice      = smp.losses.DiceLoss(mode='multiclass', classes=[1, 2, 3], log_loss=False, from_logits=True, smooth=1.0, eps=1e-07)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "iou       = smp.losses.JaccardLoss(mode='multiclass', classes=[1, 2, 3], log_loss=False, smooth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительное обучение для инициализации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.segmentation_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.segmentation_head.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "print('start at', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "for batch in loader_train:\n",
    "    model.zero_grad()\n",
    "    pred = model.forward(batch['image'].to(DEVICE))\n",
    "    mask = batch['mask'].to(DEVICE)\n",
    "\n",
    "    dc = dice(pred, mask.long())\n",
    "    y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "    y_true = (mask > 0).float()\n",
    "    bce = criterion(y_pred, y_true)\n",
    "\n",
    "    loss = dc + bce * 0.3\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print('done at', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем только декодер + голову сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head + decoder train\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in list(model.decoder.parameters()) + list(model.segmentation_head.parameters()):\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.decoder.parameters()) + list(model.segmentation_head.parameters()),\n",
    "                             lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                                 T_0=5, \n",
    "                                                                 T_mult=1, \n",
    "                                                                 eta_min=1e-6,\n",
    "                                                                 last_epoch=-1) \n",
    "print('start at', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "best_metric = 0.0\n",
    "for epoch in range(20):\n",
    "    losses     = []\n",
    "    losses_bce = []\n",
    "    losses_dc  = []\n",
    "\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    for batch in loader_train:\n",
    "        model.zero_grad()\n",
    "        pred = model.forward(batch['image'].to(DEVICE))\n",
    "        mask = batch['mask'].to(DEVICE)\n",
    "        \n",
    "        dc = dice(pred, mask.long())\n",
    "        y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "        y_true = (mask > 0).float()\n",
    "        bce = criterion(y_pred, y_true)\n",
    "        \n",
    "        loss = dc + bce * 0.3\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        losses_bce.append(bce.item())\n",
    "        losses_dc.append(dc.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(np.mean(losses))\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"),\n",
    "          f'epoch {epoch:02d} loss {np.mean(losses):.3f} bce {np.mean(losses_bce):.3f} '\n",
    "          f'dice {np.mean(losses_dc):.3f}')\n",
    "\n",
    "    val_losses    = []\n",
    "    val_losses_bce = []\n",
    "    val_losses_dc = []\n",
    "    metrics       = []\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_val:\n",
    "            pred = model.forward(batch['image'].to(DEVICE))\n",
    "            mask = batch['mask'].to(DEVICE)\n",
    "\n",
    "            dc = dice(pred, mask.long())\n",
    "            y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "            y_true = (mask > 0).float()\n",
    "            bce = criterion(y_pred, y_true)\n",
    "\n",
    "            loss = dc + bce * 0.3\n",
    "            metric = 1 - iou(pred, mask.long()).item()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_losses_bce.append(bce.item())\n",
    "            val_losses_dc.append(dc.item())\n",
    "\n",
    "            metrics.append(metric)\n",
    "\n",
    "    if best_metric <= np.mean(metrics):\n",
    "        best_metric = np.mean(metrics)\n",
    "        torch.save(model.state_dict(), f\"{ARCH}_{ENCODER}_{VERSION}_1.pth\")\n",
    "        torch.save(model.state_dict(), f\"{ARCH}_{ENCODER}_{VERSION}_{best_metric:.4f}.pth\")\n",
    "\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"), f'valid   loss {np.mean(val_losses):.3f} bce {np.mean(val_losses_bce):.3f} '\n",
    "          f'dice {np.mean(val_losses_dc):.3f} metric {np.mean(metrics):.3f}')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('done at', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной цикл обучения (4 дня)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(\n",
    "  dataset_train,\n",
    "  batch_size=2,\n",
    "  shuffle=True,\n",
    "  num_workers=2,\n",
    "  drop_last=True,\n",
    ")\n",
    "\n",
    "loader_val = DataLoader(\n",
    "  dataset_val,\n",
    "  batch_size=4,\n",
    "  shuffle=False,\n",
    "  num_workers=4,\n",
    "  drop_last=False,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{ARCH}_{ENCODER}_{VERSION}_1.pth\", map_location='cpu'))\n",
    "seed_everything(SEED)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                                 T_0=5, \n",
    "                                                                 T_mult=1, \n",
    "                                                                 eta_min=1e-6,\n",
    "                                                                 last_epoch=-1) \n",
    "\n",
    "accumulation_steps = 8\n",
    "\n",
    "print('start at', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "best_metric = 0.0\n",
    "for epoch in range(80):\n",
    "    losses     = []\n",
    "    losses_bce = []\n",
    "    losses_dc  = []\n",
    "\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    for i, batch in enumerate(loader_train, start=1):\n",
    "        pred = model.forward(batch['image'].to(DEVICE))\n",
    "        mask = batch['mask'].to(DEVICE)\n",
    "        \n",
    "        dc = dice(pred, mask.long())\n",
    "        y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "        y_true = (mask > 0).float()\n",
    "        bce = criterion(y_pred, y_true)\n",
    "        \n",
    "        loss = (dc + bce * 0.3) / accumulation_steps\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        losses_bce.append(bce.item())\n",
    "        losses_dc.append(dc.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        if i % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "        \n",
    "    scheduler.step(np.mean(losses))\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"),\n",
    "          f'epoch {epoch:02d} loss {np.mean(losses):.3f} bce {np.mean(losses_bce):.3f} '\n",
    "          f'dice {np.mean(losses_dc):.3f}')\n",
    "\n",
    "    val_losses     = []\n",
    "    val_losses_bce = []\n",
    "    val_losses_dc  = []\n",
    "    metrics        = []\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_val:\n",
    "            pred = model.forward(batch['image'].to(DEVICE))\n",
    "            mask = batch['mask'].to(DEVICE)\n",
    "\n",
    "            dc = dice(pred, mask.long())\n",
    "            y_pred = (pred.argmax(dim=1) > 0).float()\n",
    "            y_true = (mask > 0).float()\n",
    "            bce = criterion(y_pred, y_true)\n",
    "\n",
    "            loss = dc + bce * 0.3\n",
    "            metric = 1 - iou(pred, mask.long()).item()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_losses_bce.append(bce.item())\n",
    "            val_losses_dc.append(dc.item())\n",
    "\n",
    "            metrics.append(metric)\n",
    "\n",
    "    if best_metric <= np.mean(metrics):\n",
    "        best_metric = np.mean(metrics)\n",
    "        torch.save(model.state_dict(), f\"{ARCH}_{ENCODER}_{VERSION}_2.pth\")\n",
    "        torch.save(model.state_dict(), f\"{ARCH}_{ENCODER}_{VERSION}_{best_metric:.4f}.pth\")\n",
    "\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"), f'valid   loss {np.mean(val_losses):.3f} bce {np.mean(val_losses_bce):.3f} '\n",
    "          f'dice {np.mean(val_losses_dc):.3f} metric {np.mean(metrics):.3f}')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print('done at', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем маски для тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = A.Compose([\n",
    "    A.Resize(640, 864),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{ARCH}_{ENCODER}_{VERSION}_2.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    for i, image_path in enumerate(sorted(test_image_path.glob(\"*.png\"))):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i:04d} {image_path}\")\n",
    "\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        img  = transform_test(image=img)['image'].unsqueeze(0).to(DEVICE)\n",
    "        pred = model.forward(img)\n",
    "        mask = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        mask[mask == 1] = 6\n",
    "        mask[mask == 2] = 7\n",
    "        mask[mask == 3] = 10\n",
    "        \n",
    "        mask = cv2.resize(mask, (w, h), 0, 0, interpolation=cv2.INTER_NEAREST)\n",
    "                \n",
    "        cv2.imwrite('mask/' + image_path.name, mask)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "RZD_baseline.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
