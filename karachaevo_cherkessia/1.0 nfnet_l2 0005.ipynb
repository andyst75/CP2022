{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab56cd7-1da8-41f8-93ae-9c1f6d3846e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "LR   = 5e-5\n",
    "SEED = 5\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE  = 32\n",
    "NUM_WORKERS =  4\n",
    "\n",
    "MODEL_NAME = f'nfnet_l2-{SEED:04d}'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "cv2.setNumThreads(4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('DEVICE =', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd2affc-404d-4f45-89db-11d469c78b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2138.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2140.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2141.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2142.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_img  class\n",
       "0  2138.jpg      4\n",
       "1  2139.jpg      6\n",
       "2  2140.jpg      3\n",
       "3  2141.jpg      6\n",
       "4  2142.jpg      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['class'] = df['class'].values.astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827e0c4f-0021-4ae9-abbe-963b5b39b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3072, out_features=8, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "img_model = timm.create_model('eca_nfnet_l2', pretrained=True)\n",
    "in_features = img_model.head.fc.in_features\n",
    "img_model.head.fc = nn.Linear(in_features, 8)\n",
    "\n",
    "img_model.head.fc.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8dd5ef-73ac-4630-a72c-ab21f1cdf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 img_model,\n",
    "                 classes: int = df['class'].nunique(),\n",
    "                 in_features:int = in_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.img_model = img_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.img_model(x)\n",
    "\n",
    "\n",
    "model = Model(img_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04588d6-3079-4012-8143-a2e61fec4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.LongestMaxSize(160, interpolation=cv2.INTER_AREA),\n",
    "    A.PadIfNeeded(160, 160),\n",
    "    A.CoarseDropout(p=0.2),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.1),\n",
    "    A.ColorJitter(p=0.5),\n",
    "    A.ImageCompression(quality_lower=30, quality_upper=100, p=0.5),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=5, p=0.1),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05,\n",
    "                       scale_limit=0.10,\n",
    "                       rotate_limit=7.0,\n",
    "                       p=0.3),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=1),\n",
    "        A.Perspective(p=1),\n",
    "        A.GridDistortion(p=1),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(p=1),\n",
    "        A.Emboss(p=1),\n",
    "        A.RandomBrightnessContrast(p=1),\n",
    "    ], p=0.2),\n",
    "    A.Normalize(mean=img_model.pretrained_cfg['mean'],\n",
    "                std =img_model.pretrained_cfg['std']),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.LongestMaxSize(160, interpolation=cv2.INTER_AREA),\n",
    "    A.PadIfNeeded(160, 160),\n",
    "    A.Normalize(mean=img_model.pretrained_cfg['mean'],\n",
    "                std =img_model.pretrained_cfg['std']),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7670930-9546-4787-8512-2f9f925b5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame,\n",
    "                 transforms: A.Compose = None,\n",
    "                 mode: str = 'train'):\n",
    "\n",
    "        self.mode = mode\n",
    "        self.cls  = dataframe['class'].values\n",
    "        self.imgs = dataframe['ID_img'].apply(lambda x: os.path.join(mode, f'{x}')).values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx) -> dict:\n",
    "\n",
    "        image_path = self.imgs[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        item = {'image': image}\n",
    "        if self.transforms is not None:\n",
    "            item = self.transforms(**item)\n",
    "        \n",
    "        item['trg_cls']   = torch.tensor(self.cls[idx]).long()\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "dataset_train = Dataset(df, transforms=transform_train, mode='train')\n",
    "dataset_valid = Dataset(df, transforms=transform_val, mode='train')\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE,\n",
    "                                           num_workers=NUM_WORKERS, shuffle=True,\n",
    "                                           drop_last=True, pin_memory=True)\n",
    "\n",
    "loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=BATCH_SIZE,\n",
    "                                           num_workers=NUM_WORKERS, shuffle=False,\n",
    "                                           drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41feb099-ca6c-461e-bfe3-c2dfa2bf0807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1 at 21:42:01, lr=0.00000200\n",
      "  train loss: cls = 1.9619\n",
      "  valid f1:   cls = 0.5292\n",
      "Saved best model!\n",
      "Start epoch 2 at 21:44:22, lr=0.00002600\n",
      "  train loss: cls = 0.5773\n",
      "  valid f1:   cls = 0.9714\n",
      "Saved best model!\n",
      "Start epoch 3 at 21:46:50, lr=0.00005000\n",
      "  train loss: cls = 0.2016\n",
      "  valid f1:   cls = 0.9863\n",
      "Saved best model!\n",
      "Start epoch 4 at 21:49:28, lr=0.00004753\n",
      "  train loss: cls = 0.1072\n",
      "  valid f1:   cls = 0.9973\n",
      "Saved best model!\n",
      "Start epoch 5 at 21:52:05, lr=0.00004062\n",
      "  train loss: cls = 0.0721\n",
      "  valid f1:   cls = 0.9973\n",
      "Start epoch 6 at 21:54:40, lr=0.00003064\n",
      "  train loss: cls = 0.0473\n",
      "  valid f1:   cls = 0.9990\n",
      "Saved best model!\n",
      "Start epoch 7 at 21:56:57, lr=0.00001956\n",
      "  train loss: cls = 0.0298\n",
      "  valid f1:   cls = 0.9997\n",
      "Saved best model!\n",
      "Start epoch 8 at 21:59:00, lr=0.00000958\n",
      "  train loss: cls = 0.0320\n",
      "  valid f1:   cls = 0.9992\n",
      "Start epoch 9 at 22:01:19, lr=0.00000267\n",
      "  train loss: cls = 0.0314\n",
      "  valid f1:   cls = 0.9997\n",
      "Saved best model!\n",
      "Start epoch 10 at 22:03:40, lr=0.00000020\n",
      "  train loss: cls = 0.0148\n",
      "  valid f1:   cls = 0.9997\n",
      "Saved best model!\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, epochs=EPOCHS, max_lr=LR,\n",
    "                                                   div_factor=25.0, final_div_factor=10.0, steps_per_epoch=1)\n",
    "\n",
    "best_cnt = 0\n",
    "best_f1  = 0.0\n",
    "\n",
    "weight = len(df) / (len(np.unique(df['class'].values)) * np.bincount(df['class'].values))\n",
    "weight = torch.FloatTensor(weight)\n",
    "weight = torch.nan_to_num(weight, posinf=1.0, neginf=1.0)\n",
    "weight = weight.cuda()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    criterion  = nn.CrossEntropyLoss(weight)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Start epoch {epoch + 1} at {datetime.now().strftime('%H:%M:%S')}, lr={current_lr:0.8f}\")\n",
    "\n",
    "    loss_cls = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for batch in loader_train:\n",
    "        batch = {k:v.cuda() for k, v in batch.items()}\n",
    "        \n",
    "        pred = model(batch['image'])\n",
    "        loss = criterion(pred, batch['trg_cls'])\n",
    "\n",
    "        loss_cls.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "\n",
    "    val_cls = []\n",
    "    trg_cls = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_valid:\n",
    "            batch = {k:v if k.startswith('trg_') else v.cuda() for k, v in batch.items()}\n",
    "            pred = model(batch['image'])\n",
    "\n",
    "            trg_cls.extend(batch['trg_cls'].numpy().tolist())\n",
    "            val_cls.extend(pred.argmax(dim=1).cpu().numpy().tolist())\n",
    "\n",
    "    f1_cls  = f1_score(trg_cls, val_cls, zero_division=0, average='macro')\n",
    "\n",
    "    print(f\"  train loss: cls = {min(9.9999, np.mean(loss_cls)):6.4f}\")\n",
    "    print(f\"  valid f1:   cls = {f1_cls:6.4f}\")\n",
    "\n",
    "    best_cnt += 1\n",
    "    if f1_cls >= best_f1:\n",
    "        best_cnt = 0\n",
    "        best_f1 = f1_cls\n",
    "        torch.save(model.state_dict(), f\"{MODEL_NAME}.pth\")\n",
    "        torch.save(model.state_dict(), f\"{MODEL_NAME}_{epoch}.pth\")\n",
    "        print(\"Saved best model!\")\n",
    "    elif best_cnt > EPOCHS // 5:\n",
    "        best_cnt = 0\n",
    "        print(\"Loading best model weights!\")\n",
    "        model.load_state_dict(torch.load(f\"{MODEL_NAME}.pth\", map_location=device))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
