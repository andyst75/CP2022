{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d115284-7aee-41b3-9e0f-07dcae95085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"../train/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data = []\n",
    "for cl in [0, 1, 2]:\n",
    "    for image_name in glob.glob(f\"../2906/{cl}/*.jpg\"):\n",
    "        data.append({\"ID_img\":Path(image_name).name, \"class\":cl})\n",
    "    for image_name in glob.glob(f\"../2906/{cl}/*.jpeg\"):\n",
    "        data.append({\"ID_img\":Path(image_name).name, \"class\":cl})\n",
    "data_df = pd.DataFrame(data)\n",
    "\n",
    "dataset    = ImageDataset(data_df, transform_valid)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                       batch_size=2,\n",
    "                                       shuffle=False,\n",
    "                                       pin_memory=True,\n",
    "                                       num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb94c448-85f7-4bcf-a83a-ac60d6686518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/000_2906.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andyst/anaconda3/envs/lab/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/001_2906.pth\n",
      "checkpoints/002_2906.pth\n",
      "checkpoints/003_2906.pth\n",
      "checkpoints/004_2906.pth\n",
      "checkpoints/005_2906.pth\n",
      "checkpoints/006_2906.pth\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for models in glob.glob(f\"checkpoints/*.pth\"):\n",
    "    print(models)\n",
    "    torch.cuda.empty_cache()\n",
    "    model = timm.models.swin_large_patch4_window12_384(pretrained=False)\n",
    "    model.head = nn.Sequential(nn.Linear(model.head.weight.shape[1], 4096),\n",
    "                    nn.Dropout(0.10),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(4096, 3))\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(models))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            pred = model(imgs)\n",
    "            preds.extend(pred.cpu().numpy().tolist())\n",
    "    res.append({'models': models, 'preds': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f98675-eb17-4252-a72f-fff01e3abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [x[1].item() for x in dataset]\n",
    "y_true = torch.LongTensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45f0921-b709-4c61-b87e-4411821058f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    idxs = np.random.choice(list(range(len(res))), size=5, replace=False)\n",
    "\n",
    "    model_list = []\n",
    "    for i, idx in enumerate(idxs):\n",
    "        model_list.append(res[idx]['models'])\n",
    "        if i == 0:\n",
    "            pred  = torch.sigmoid(torch.FloatTensor(res[idx]['preds']))\n",
    "        else:\n",
    "            pred += torch.sigmoid(torch.FloatTensor(res[idx]['preds']))\n",
    "\n",
    "    pred = pred.argmax(1)\n",
    "    acc = (y_true == pred).sum() / len(y_true)\n",
    "    \n",
    "    out.append((acc, model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1efd20-9b48-4f7a-9a3e-0fb16441d00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(1.),\n",
       "  ['checkpoints/006_2906.pth',\n",
       "   'checkpoints/000_2906.pth',\n",
       "   'checkpoints/001_2906.pth',\n",
       "   'checkpoints/004_2906.pth',\n",
       "   'checkpoints/005_2906.pth']),\n",
       " (tensor(1.),\n",
       "  ['checkpoints/002_2906.pth',\n",
       "   'checkpoints/001_2906.pth',\n",
       "   'checkpoints/004_2906.pth',\n",
       "   'checkpoints/005_2906.pth',\n",
       "   'checkpoints/003_2906.pth']),\n",
       " (tensor(1.),\n",
       "  ['checkpoints/006_2906.pth',\n",
       "   'checkpoints/002_2906.pth',\n",
       "   'checkpoints/005_2906.pth',\n",
       "   'checkpoints/004_2906.pth',\n",
       "   'checkpoints/003_2906.pth']),\n",
       " (tensor(1.),\n",
       "  ['checkpoints/005_2906.pth',\n",
       "   'checkpoints/001_2906.pth',\n",
       "   'checkpoints/004_2906.pth',\n",
       "   'checkpoints/003_2906.pth',\n",
       "   'checkpoints/002_2906.pth']),\n",
       " (tensor(1.),\n",
       "  ['checkpoints/005_2906.pth',\n",
       "   'checkpoints/002_2906.pth',\n",
       "   'checkpoints/004_2906.pth',\n",
       "   'checkpoints/006_2906.pth',\n",
       "   'checkpoints/001_2906.pth'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = sorted(out, key=lambda x: -x[0])\n",
    "out[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e17592b-e24c-4605-9174-5ac6b731224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../sample_solution.csv\")\n",
    "test_df = test_df.drop([\"class\"], axis = 1)\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['ID_img']\n",
    "        \n",
    "        # читаем картинку\n",
    "        image = cv2.imread(f\"../test/{image_name}.jpg\")\n",
    "        if image is None:\n",
    "            print(f\"{image_name} is empty\")\n",
    "            return torch.zeros(3, 384, 384)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            # преобразуем, если нужно\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "\n",
    "test_dataset = TestImageDataset(test_df, valid_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=2,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e556a2-ef87-4125-b6a6-60a7b176b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40567458052_99667140804_20508599954_6 is empty\n",
      "40567458052_99667140804_20508599954_6 is empty\n",
      "40567458052_99667140804_20508599954_6 is empty\n",
      "40567458052_99667140804_20508599954_6 is empty\n",
      "40567458052_99667140804_20508599954_6 is empty\n"
     ]
    }
   ],
   "source": [
    "test_out = []\n",
    "for i, modelname in enumerate(out[0][1]):\n",
    "    torch.cuda.empty_cache()\n",
    "    model = timm.models.swin_large_patch4_window12_384(pretrained=False)\n",
    "    model.head = nn.Sequential(nn.Linear(model.head.weight.shape[1], 4096),\n",
    "                    nn.Dropout(0.10),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(4096, 3))\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in test_loader:\n",
    "            imgs = imgs.cuda()\n",
    "            pred.append(model(imgs).cpu().detach().numpy())\n",
    "            \n",
    "    if i == 0:\n",
    "        test_out  = np.vstack(pred)\n",
    "    else:\n",
    "        test_out += np.vstack(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb9c448-ed14-490a-8409-24fb3cff89fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_img</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34020749806_42065966214_42113475048_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80128313599_98196458454_79029076007_8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17820331238_48919943775_53688855463_7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70492442702_21083599816_22777758696_0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94790217016_17108156014_60668676818_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>60879177998_15763718934_82574532042_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11758169966_65799840524_72283028069_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>9259096884_2251720133_44072689872_8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>37732252922_9265441355_19052721018_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>26230096975_1198032682_52245678077_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ID_img  class\n",
       "0    34020749806_42065966214_42113475048_2      2\n",
       "1    80128313599_98196458454_79029076007_8      1\n",
       "2    17820331238_48919943775_53688855463_7      2\n",
       "3    70492442702_21083599816_22777758696_0      2\n",
       "4    94790217016_17108156014_60668676818_2      2\n",
       "..                                     ...    ...\n",
       "220  60879177998_15763718934_82574532042_2      2\n",
       "221  11758169966_65799840524_72283028069_1      1\n",
       "222    9259096884_2251720133_44072689872_8      0\n",
       "223   37732252922_9265441355_19052721018_3      1\n",
       "224   26230096975_1198032682_52245678077_3      1\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = np.argmax(test_out, axis=1)\n",
    "test_names = test_df[\"ID_img\"]\n",
    "\n",
    "submit_df = pd.DataFrame([[name, pred] for name, pred in zip(test_names, predicts)], columns=['ID_img', 'class'])\n",
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db89f635-5bf6-4f10-afbc-48ae070cec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(f\"timm_cv7_best5_2906v8.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
