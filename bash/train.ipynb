{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c01655-551d-479b-ba0b-62c9201b2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "SEED = 111\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name, label = self.data_df.iloc[idx]['ID_img'], self.data_df.iloc[idx]['class']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"../train/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # преобразуем, если нужно. transform it, if necessary\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomAffine(15,  translate=(0.15, 0.15)),\n",
    "    transforms.RandomResizedCrop((384, 384), scale=(0.70, 1.3)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.RandomVerticalFlip(0.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "data = []\n",
    "for cl in [0, 1, 2]:\n",
    "    for image_name in glob.glob(f\"../2906/{cl}/*.jpg\"):\n",
    "        data.append({\"ID_img\":Path(image_name).name, \"class\":cl})\n",
    "    for image_name in glob.glob(f\"../2906/{cl}/*.jpeg\"):\n",
    "        data.append({\"ID_img\":Path(image_name).name, \"class\":cl})\n",
    "data_df = pd.DataFrame(data)\n",
    "\n",
    "full_dataset_train = ImageDataset(data_df, transform_train)\n",
    "full_dataset_val   = ImageDataset(data_df, transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a43402d-c455-414a-86df-bfc9d9593887",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_idx = []\n",
    "for rnd in [SEED]:\n",
    "    cv = KFold(n_splits=7, random_state=rnd, shuffle=True)\n",
    "    fold_idx.append(list(cv.split(data_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f28517-a67b-49f5-9707-031969e2f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module, criterion, optimizer, train_dataloader, test_dataloader, epochs:int=10, is_init:bool=False, it=0):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    \n",
    "    train_acc_log = []\n",
    "    val_acc_log = []\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_size = 0\n",
    "        \n",
    "        train_pred = 0.\n",
    "\n",
    "        for imgs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_size += y_pred.size(0)\n",
    "            train_loss_log.append(loss.data / y_pred.size(0))\n",
    "            \n",
    "            train_pred += (y_pred.argmax(1) == labels).sum()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        if is_init:\n",
    "            continue\n",
    "\n",
    "        train_acc_log.append(train_pred / train_size)\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_size = 0\n",
    "        \n",
    "        val_pred = 0.\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_dataloader:\n",
    "                \n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_size += pred.size(0)\n",
    "                \n",
    "                val_pred += (pred.argmax(1) == labels).sum()\n",
    "        \n",
    "\n",
    "        val_loss_log.append(val_loss / val_size)\n",
    "        val_acc_log.append(val_pred / val_size)\n",
    "        \n",
    "        if best_acc <= val_pred / val_size:\n",
    "            best_acc = val_pred / val_size\n",
    "            \n",
    "            torch.save(model.state_dict(), f\"checkpoints/{it:03d}_2906.pth\")\n",
    "\n",
    "    if not is_init:\n",
    "        return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc285cac-6823-402d-8e0b-21a0d169f933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start iter 0\n",
      "start fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andyst/anaconda3/envs/lab/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2650.9 sec, best acc 0.974\n",
      "start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2674.6 sec, best acc 0.949\n",
      "start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2668.2 sec, best acc 0.949\n",
      "start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2657.8 sec, best acc 0.962\n",
      "start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2674.0 sec, best acc 0.961\n",
      "start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2664.5 sec, best acc 0.974\n",
      "start fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models.helpers:Loading pretrained weights from url (https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2666.4 sec, best acc 0.961\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "\n",
    "for i, fold in enumerate(fold_idx[start_idx:], start=start_idx):\n",
    "    print(f'start iter {i}')\n",
    "    val_preds = np.zeros((len(data_df), 3))\n",
    "    train_preds = np.zeros((len(data_df), 3))\n",
    "    for y, (train_idx, val_idx) in enumerate(fold):\n",
    "        print(f'start fold {y}')\n",
    "        start = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        model = timm.models.swin_large_patch4_window12_384(pretrained=True)\n",
    "        model.head = nn.Sequential(nn.Linear(model.head.weight.shape[1], 4096),\n",
    "                        nn.Dropout(0.20),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(4096, 3))\n",
    "        nn.init.xavier_normal_(model.head[0].weight)\n",
    "        nn.init.zeros_(model.head[0].bias)\n",
    "        nn.init.xavier_normal_(model.head[-1].weight)\n",
    "        nn.init.zeros_(model.head[-1].bias)\n",
    "        model = model.cuda()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        dataset_train = Subset(full_dataset_train, train_idx)\n",
    "        dataset_val   = Subset(full_dataset_val, val_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                           batch_size=6,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=6)\n",
    "\n",
    "        valid_loader = torch.utils.data.DataLoader(dataset=dataset_val,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=False,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=4)\n",
    "        optimizer = torch.optim.AdamW(model.head.parameters(), lr=1e-5)\n",
    "\n",
    "        train(model, criterion, optimizer, train_loader, valid_loader, epochs=1, is_init=True)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.head.parameters(), lr=1e-4)\n",
    "        best_acc = train(model, criterion, optimizer, train_loader, valid_loader, epochs=40, it=i * 100 + y)\n",
    "\n",
    "        model.cpu()\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(f\"total {time.time() - start:.1f} sec, best acc {best_acc:.3f}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
